{"cells":[{"cell_type":"markdown","metadata":{"id":"4mB_sFildiDh"},"source":["<a href=\"https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_2_train_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{},"source":["### 01. Clone the repo and install `ninja`\n","\n","Paperspace has a built-in PyTorch version already installed depending on your configuration.\n","\n","Make sure to prepare a notebook with torch>=1.9.0."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":112689,"status":"ok","timestamp":1648268462502,"user":{"displayName":"秋山翔","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdguDmy9xnCw5NJJf4uTTTTTCxznQtGcQAx-nmfA=s64","userId":"04732984829971845767"},"user_tz":-540},"id":"9LVr5sV8CKz0","outputId":"bd4471e2-208c-403f-f846-adfd4cc35292"},"outputs":[],"source":["!git clone https://github.com/NVlabs/stylegan3.git\n","!pip install ninja"]},{"cell_type":"markdown","metadata":{},"source":["### 02. Create folders for training\n","\n","Create a folder structure in your Paperspace gradient notebook file system:\n","\n","```\n","├── stylegan\n","│   ├── images\n","│   │   ├── <Your dataset folder containing images with dimensions of power of 2 (ex. - 64x64, 128x128, 1024x1024)>\n","│   ├── datasets\n","│   ├── experiments\n","```\n","\n","You can use [ImageMagick's](https://imagemagick.org/) batch image processor script `mogrify` locally before uploading to make sure all your images have a power-of-two dimension. You can also use PIL to do this as well.\n","\n","Take note of your raw dataset folder name and put it in the `RAW_DATASET_FOLDER_NAME` variable below.\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1185,"status":"ok","timestamp":1647884458731,"user":{"displayName":"秋山翔","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdguDmy9xnCw5NJJf4uTTTTTCxznQtGcQAx-nmfA=s64","userId":"04732984829971845767"},"user_tz":-540},"id":"wwpXtlrCCRHe","outputId":"930c9173-03b6-4f93-8765-f81bebee84c8"},"outputs":[],"source":["import os\n","\n","# Change this to your dataset folder name\n","RAW_DATASET_FOLDER_NAME = \"faces\" \n","\n","STYLEGAN_ROOT_FOLDER = os.path.join(\n","    os.sep, \"notebooks\", \"stylegan\"\n",")\n","RAW_DATASET_PATH = os.path.join(STYLEGAN_ROOT_FOLDER, \"images\", RAW_DATASET_FOLDER_NAME)\n","ZIP_DATASET_PATH = os.path.join(STYLEGAN_ROOT_FOLDER, \"datasets\", RAW_DATASET_FOLDER_NAME)\n","EXPERIMENTS_PATH = os.path.join(STYLEGAN_ROOT_FOLDER, \"experiments\")\n","\n","STYLEGAN_PATH = os.path.join(os.sep, \"notebooks\", \"stylegan3\")\n","DATASET_TOOL_PATH = os.path.join(STYLEGAN_PATH, \"dataset_tool.py\")\n","TRAINING_SCRIPT_PATH = os.path.join(STYLEGAN_PATH, \"train.py\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qOK8m0N-Caqa"},"outputs":[],"source":["dataset_creation_cmd = f\"python {DATASET_TOOL_PATH} --source={RAW_DATASET_PATH} --dest={ZIP_DATASET_PATH}\"\n","!{dataset_creation_cmd}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QuWfEfEoColz"},"outputs":[],"source":["# Verifies your dataset for inconsistent sizes and colour formats\n","# Script created by @jeffheaton\n","\n","from os import listdir\n","from os.path import isfile, join\n","import os\n","from PIL import Image\n","from tqdm import tqdm\n","\n","\n","files = [f for f in listdir(RAW_DATASET_PATH) if isfile(join(RAW_DATASET_PATH, f))]\n","\n","base_size = None\n","for file in tqdm(files):\n","    file2 = os.path.join(RAW_DATASET_PATH, file)\n","    img = Image.open(file2)\n","    sz = img.size\n","    if base_size and sz != base_size:\n","        print(f\"Inconsistant size: {file2}\")\n","    elif img.mode != \"RGB\":\n","        print(f\"Inconsistant color format: {file2}\")\n","    else:\n","        base_size = sz"]},{"cell_type":"markdown","metadata":{},"source":["### 03. Training\n","\n","You can play around with different configurations here. A few descriptions:\n","\n","- `CFG` - you can pick `stylegan3-t` (only designed for translation equivariance) or `stylegan3-r` (features high-quality, though not visually perfect rotation equivariance). More details in the [official NVIDIA StyleGAN3 documentation](https://nvlabs.github.io/stylegan3/)\n","- `BATCH_SIZE` - the number of samples that will be passed through to the network at one time\n","- `BATCH_GPU` - per-GPU batch size\n","- `GAMMA` - R1 regularization weight\n","- `SNAP` - number of epochs before saving a new checkpoint in the `experiments` folder on Google Drive (for Google Colab Free, it is recommended to keep this low, say `5` or `10`)\n","\n","You can refer to the [official documentation's recommended configurations](https://github.com/NVlabs/stylegan3/blob/main/docs/configs.md#recommended-configurations) to see more config parameters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4-ZBcql7Cv14"},"outputs":[],"source":["import os\n","\n","# Modify these to suit your needs\n","CFG = \"stylegan3-t\"\n","BATCH_SIZE = 32\n","BATCH_GPU = 16\n","GAMMA = 0.5\n","SNAP = 10\n","\n","# Build the command and run it\n","cmd = f\"python stylegan3/train.py --outdir={EXPERIMENTS_PATH} --data={ZIP_DATASET_PATH} --cfg={CFG} --gpus=1 --workers=1 --batch={BATCH_SIZE} --batch-gpu={BATCH_GPU} --gamma={GAMMA} --snap={SNAP}\"\n","!{cmd}"]},{"cell_type":"markdown","metadata":{},"source":["### 04. Resuming training\n","\n","Your Paperspace instance will automatically be turned off after some time depending on your auto-shutdown setting (Max 6 hours for free instances).\n","You can resume training with the code below.\n","\n","Check your experiments folder to check the `CHECKPOINT_FOLDER` and `NETWORK` name in the `experiments` folder.\n","An example of this is:\n","\n","```\n","├── stylegan\n","│   ├── images\n","│   ├── dataset\n","│   ├── experiments\n","│   │   ├── 00002-dogs_images-auto1-resumecustom --> This is the `CHECKPOINT_FOLDER`\n","│   │   │   ├── network-snapshot-000160.pkl --> This is the `NETWORK`\n","```\n","\n","You can use the `NETWORK` with the latest epoch to continue.\n","The confgurations are the same as the ones in *04. Training*."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P1TFgr9MDJlS","outputId":"fc835169-dd7c-49ba-9383-1676dd59d3cd"},"outputs":[],"source":["# Resume Training\n","\n","import os\n","\n","# Modify these to suit your needs\n","CHECKPOINT_FOLDER = \"<CHANGE_ME>\"\n","NETWORK = \"<CHANGE_ME>\"\n","\n","RESUME = os.path.join(EXPERIMENTS_PATH, CHECKPOINT_FOLDER, NETWORK)\n","CFG = \"stylegan3-t\"\n","BATCH_SIZE = 32\n","BATCH_GPU = 16\n","GAMMA = 0.5\n","SNAP = 10\n","\n","# Build the command and run it\n","cmd = f\"python stylegan3/train.py --resume={RESUME} --outdir={EXPERIMENTS_PATH} --data={ZIP_DATASET_PATH} --cfg={CFG} --gpus=1 --workers=1 --batch={BATCH_SIZE} --batch-gpu={BATCH_GPU} --gamma={GAMMA} --snap={SNAP}\"\n","!{cmd}"]}],"metadata":{"accelerator":"GPU","anaconda-cloud":{},"colab":{"collapsed_sections":[],"name":"stylegan_custom_dataset.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":0}
